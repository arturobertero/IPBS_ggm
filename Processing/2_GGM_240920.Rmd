---
title: "3_IPBS_mgm_230912"
author: "Arturo Bertero"
date: "2023-09-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(pacman)
p_load(tidyverse, here, sjlabelled, stringr, glue, EGAnet, janitor, haven,
       ggpubr, gridExtra, dplyr, GGally, qgraph, sjmisc, igraph,
       sjPlot, sna, grid, psych, stargazer, mgm, backbone, ggplot2, tnet,
       ggrepel, EGAnet, NetworkComparisonTest, Matrix, bootnet, matrixcalc, 
       openxlsx, devtools, jtools, corrr, patchwork, magick, hrbrthemes)

options(scipen=999)
```

# Input

```{r}
#Load data
IPBS = readRDS((here("Input", "IPBS.rds")))

#Filter smaller dataset
att = IPBS %>% 
  dplyr::select(c(L_R:ukrai)) 

#Partitions
load(file = here("Input", "Partitions", "pol_int_partitions.RData"))
load(file = here("Input", "Partitions", "pol_int_partitions_2_1.RData"))
load(file = here("Input", "Partitions", "pol_int_partitions_2_2.RData"))
load(file = here("Input", "Partitions", "educ_partitions.RData"))
load(file = here("Input", "Partitions", "vote_partitions.RData"))

#Fast running (run [0] or skip [1] bootnet and NCT)
fast_running = 1
```

# Processing

##  Cor network estimation 

```{r}
# Define shortnames, longnames, and groupings as per your original code
shortnames <- names(att)
longnames <- c("Left right","Propensity to vote for PD",
               "Propensity to vote for FI","Propensity to vote for L",
               "Propensity to vote for M5S","Propensity to vote for FDI",
               "Step child adoption","Abortion","Euthanasia","Omosexual marriage",
               "Redistribution","Flat tax","Minimum wage","Citizenship income",
               "Globalization","Immigration","Big government",
               "Public vs private","Weapons to Ukraine")

Totalgroup_comm <- list(
  "Symbolic" = c(1:6),
  "Operational" = c(7:19)
)

Totalgroup_cols <- c("#966FD6B3","#008B8BB3")  
```

```{r}
# estimation on att

#remove labels
att = sapply(att, haven::zap_labels)

#declare operational or symbolic
nature = c(rep("Symbolic", 6),
            rep("Operational", 13))

#Fit cor network 
att_net = cor_auto(att, npn.SKEPTIC = T, #Nonparanormal transformation (HUGE)
                        ordinalLevelMax = 7, #from keskinturk
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE)

#square the matrix
att_net = att_net^2

#plot
qgraph(att_net,
         fade = TRUE, layout = "spring", theme = "colorblind",  
         labels = shortnames, nodeNames = longnames,
         vsize = 7.0, label.cex = 1.1, esize = 15, vTrans = 255,
         groups = Totalgroup_comm, color = Totalgroup_cols,
         legend = F, legend.cex = 0.40, title = "Correlational network",
         filetype = "jpg", filename = here("Output", "Supplement", "att"))
```

```{r}
# Function to ensure input data is in matrix/data frame format
prepare_data <- function(data) {
  if (is.list(data)) {
    return(as.data.frame(do.call(cbind, data)))  # Convert list to data frame
  } else if (is.vector(data)) {
    return(as.data.frame(matrix(data, nrow = length(data))))  # Convert vector to a data frame
  } else {
    return(as.data.frame(data))  # Already in correct format
  }
}

# Function to fit and plot correlation networks and save the plots to a file
generate_network_plots <- function(low_data, high_data, shortnames, longnames, group_names, group_colors, title_low, title_high, file_base) {
  # Remove labels
  low_data <- sapply(low_data, haven::zap_labels)
  high_data <- sapply(high_data, haven::zap_labels)
  
  # Fit GGM for low data
  low_data_net <- cor_auto(low_data, npn.SKEPTIC = TRUE, ordinalLevelMax = 7, forcePD = TRUE, missing = "pairwise", verbose = FALSE)
  low_data_net <- low_data_net^2  # Square the matrix
  
  # Fit GGM for high data
  high_data_net <- cor_auto(high_data, npn.SKEPTIC = TRUE, ordinalLevelMax = 7, forcePD = TRUE, missing = "pairwise", verbose = FALSE)
  high_data_net <- high_data_net^2  # Square the matrix
  
  # Save plot for low data
  set.seed(1)
  qgraph(low_data_net,
         fade = TRUE, layout = "spring", theme = "colorblind",  
         labels = shortnames, nodeNames = longnames,
         vsize = 7.0, label.cex = 1.1, esize = 15, vTrans = 255,
         groups = group_names, color = group_colors,
         legend = F, legend.cex = 0.40, title = title_low,
         filetype = "jpg", filename = here("Output", "Supplement", paste0(file_base, "_Low")))
  
  # Save plot for high data
  set.seed(1)
  qgraph(high_data_net,
         fade = TRUE, layout = "spring", theme = "colorblind",  
         labels = shortnames, nodeNames = longnames,
         vsize = 7.0, label.cex = 1.1, esize = 15, vTrans = 255,
         groups = group_names, color = group_colors,
         legend = F, legend.cex = 0.40, title = title_high,
         filetype = "jpg", filename = here("Output", "Supplement", paste0(file_base, "_High")))
}

# Generate Political Interest plots and save them
generate_network_plots(
  low_data = prepare_data(polint_2_1_l),
  high_data = prepare_data(polint_2_1_h),
  shortnames = shortnames, 
  longnames = longnames,
  group_names = Totalgroup_comm, 
  group_colors = Totalgroup_cols, 
  title_low = "Political Interest - Low",
  title_high = "Political Interest - High",
  file_base = "Fig_Political_Interest"
)

# Generate Education plots and save them
generate_network_plots(
  low_data = prepare_data(educ_low),
  high_data = prepare_data(educ_high),
  shortnames = shortnames, 
  longnames = longnames,
  group_names = Totalgroup_comm, 
  group_colors = Totalgroup_cols, 
  title_low = "Education - Low",
  title_high = "Education - High",
  file_base = "Fig_Education"
)

```


## MGMs

```{r}
# mgm on att
  mgm_att <- mgm(att, type = rep("g", length(shortnames)), 
                   level = rep(1, length(shortnames)), lambdaSel = "EBIC", ruleReg = "OR")
  
  # Predictability
  pred_att <- predict(object = mgm_att, data = att, errorCon = 'R2')
  
  # Plot the MGM network
  graph_mgm <- qgraph(mgm_att$pairwise$wadj, layout = 'spring',
                      labels = shortnames, nodeNames = longnames,  
                      groups = Totalgroup_comm, color = Totalgroup_cols, 
                      legend = T, legend.cex = 0.33, title = "mgm",
                      edge.color = mgm_att$pairwise$edgecolor_cb, vTrans = 255,
                      borders = T, vsize = 7.0, esize = 15, GLratio = 2,
                      pie = pred_att$errors[,2], pieColor = rep('#FFFF00', length(shortnames)),
                      filetype = "jpg",  
                      filename = here("Output", "Supplement", "att_mgm"))

```


```{r}
# Function to ensure input data is in matrix format
prepare_matrix_data <- function(data) {
  if (!is.matrix(data)) {
    return(as.matrix(data))  # Convert to matrix if it's not already
  }
  return(data)
}

# Function to fit MGM and plot the results
fit_and_plot_mgm <- function(data, shortnames, longnames, mgm_groups, mgm_colors, file_base) {
  # Prepare data as a matrix
  data_matrix <- prepare_matrix_data(data)
  
  # Fit MGM model (all continuous variables)
  mgm_model <- mgm(data_matrix, type = rep("g", length(shortnames)), 
                   level = rep(1, length(shortnames)), lambdaSel = "EBIC", ruleReg = "OR")
  
  # Predictability
  pred_mgm <- predict(object = mgm_model, data = data_matrix, errorCon = 'R2')
  
  # Plot the MGM network
  graph_mgm <- qgraph(mgm_model$pairwise$wadj, layout = 'spring',
                      labels = shortnames, nodeNames = longnames,  
                      groups = mgm_groups, color = mgm_colors, 
                      legend = F, legend.cex = 0.33, vTrans = 255,
                      edge.color = mgm_model$pairwise$edgecolor_cb,
                      borders = T, vsize = 7.0, esize = 15, GLratio = 2,
                      pie = pred_mgm$errors[,2], pieColor = rep('#FFFF00', length(shortnames)),
                      filetype = "jpg",  
                      filename = here("Output", "Supplement", file_base))
}

# Fit and plot MGM for all datasets
datasets <- list(
  "pol_int_low" = polint_2_1_l,
  "pol_int_high" = polint_2_1_h,
  "educ_low" = educ_low,
  "educ_high" = educ_high
)

# Loop through datasets and apply MGM fitting and plotting
for (name in names(datasets)) {
  fit_and_plot_mgm(
    data = datasets[[name]],
    shortnames = shortnames, 
    longnames = longnames,
    mgm_groups = Totalgroup_comm, 
    mgm_colors = Totalgroup_cols, 
    file_base = paste0(name, "_mgm")
  )
}


```


## Bootstrap analyses (cor)

```{r}
if (fast_running==0) {

##############################
#Bootstrapped on full samples
##############################

#boots_att
boot_att = zap_labels(att) %>%
          data.frame()

df.boot_att = bootnet(boot_att, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)
#Save Bootnets
save(df.boot_att, file = here("Input", "Boots", "boots_att.RData"))

###############
#Bootstrap pint
###############

#low
polint_low_and_midlow = zap_labels(polint_low_and_midlow) %>%
          data.frame()
df.boot_pint_l <- bootnet(polint_low_and_midlow, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#mid
pol_int_midhigh = zap_labels(pol_int_midhigh) %>%
          data.frame()
df.boot_pint_m <- bootnet(pol_int_midhigh, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#high
pol_int_high = zap_labels(pol_int_high) %>%
          data.frame()
df.boot_pint_h <- bootnet(pol_int_high, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l,df.boot_pint_m,df.boot_pint_h,
     file = here("Input", "Boots", "boots_pint.RData"))

###############
#Bootstrap educ
###############

#low
educ_low = zap_labels(educ_low) %>%
          data.frame()
df.boot_educ_l <- bootnet(educ_low, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#high
educ_high = zap_labels(educ_high) %>%
          data.frame()
df.boot_educ_h <- bootnet(educ_high, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_educ_l,df.boot_educ_h,
     file = here("Input", "Boots", "boots_educ.RData"))

#################
#Additional pint#
#################

# On 2_1

#low
polint_l_2_1 = zap_labels(polint_2_1_l) %>%
          data.frame()
df.boot_pint_l_2_1 <- bootnet(polint_l_2_1, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#high
polint_h_2_1 = zap_labels(polint_2_1_h) %>%
          data.frame()
df.boot_pint_h_2_1 <- bootnet(polint_h_2_1, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l_2_1,df.boot_pint_h_2_1,
     file = here("Input", "Boots", "boots_pint_2_1.RData"))

# On 2_2

#low
polint_l_2_2 = zap_labels(polint_2_2_l) %>%
          data.frame()
df.boot_pint_l_2_2 <- bootnet(polint_l_2_2, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#high
polint_h_2_2 = zap_labels(polint_2_2_h) %>%
          data.frame()
df.boot_pint_h_2_2 <- bootnet(polint_h_2_2, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l_2_2,df.boot_pint_h_2_2,
     file = here("Input", "Boots", "boots_pint_2_2.RData"))

} else {
  
  #Boots
load(file = here("Input", "Boots", "boots_att.RData"))
load(file = here("Input", "Boots", "boots_pint.RData"))
load(file = here("Input", "Boots", "boots_educ.RData"))
load(file = here("Input", "Boots", "boots_pint_2_1.RData"))
load(file = here("Input", "Boots", "boots_pint_2_2.RData"))
}
```

## Bootstrap analyses (cor)

```{r}
if (fast_running==0) {

##############################
#Bootstrapped on full samples
##############################

#boots_att_pc
df.boot_att_pc <- bootnet(boot_att, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)
#Save Bootnets
save(df.boot_att_pc, file = here("Input", "Boots", "boots_att_pc.RData"))


###############
#Bootstrap pint
###############

#boots_pint_l_pc
df.boot_pint_l_pc <- bootnet(polint_low_and_midlow, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#boots_pint_m_pc
df.boot_pint_m_pc <- bootnet(pol_int_midhigh, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#boots_pint_h_pc
df.boot_pint_h_pc <- bootnet(pol_int_high, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)
#Save Bootnets 
save(df.boot_pint_l_pc,df.boot_pint_m_pc,df.boot_pint_h_pc,
     file = here("Input", "Boots", "boots_pint_pc.RData"))


###############
#Bootstrap educ
###############

#boots_educ_l_pc
df.boot_educ_l_pc <- bootnet(educ_low, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#boots_educ_h_pc
df.boot_educ_h_pc <- bootnet(educ_high, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_educ_l_pc,df.boot_educ_h_pc,
     file = here("Input", "Boots", "boots_educ_pc.RData"))



#################
#Additional pint#
#################

# On 2_1

#low
df.boot_pint_l_2_1_pc <- bootnet(polint_l_2_1, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#high
df.boot_pint_h_2_1_pc <- bootnet(polint_h_2_1, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l_2_1_pc,df.boot_pint_h_2_1_pc,
     file = here("Input", "Boots", "boots_pint_2_1_pc.RData"))

# On 2_2

#low
df.boot_pint_l_2_2_pc <- bootnet(polint_l_2_2, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#high
df.boot_pint_h_2_2_pc <- bootnet(polint_h_2_2, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l_2_2_pc,df.boot_pint_h_2_2_pc,
     file = here("Input", "Boots", "boots_pint_2_2_pc.RData"))

} else {
  
  #Boots
load(file = here("Input", "Boots", "boots_att_pc.RData"))
load(file = here("Input", "Boots", "boots_pint_pc.RData"))
load(file = here("Input", "Boots", "boots_educ_pc.RData"))
load(file = here("Input", "Boots", "boots_pint_2_1_pc.RData"))
load(file = here("Input", "Boots", "boots_pint_2_2_pc.RData"))
}
```

## Extract info from boots

```{r}
# Function to process each dataset
process_boots_data <- function(df_boot) {
  # Extract the matrices
  matrix_list <- lapply(1:10000, function(i) {
    df_boot[["boots"]][[i]][["graph"]]
  })
  
  # Calculate the mean of the squared matrix for each matrix
  mean_values <- sapply(matrix_list, function(mat) {
    squared_matrix <- mat^2
    mean(squared_matrix)
  })
  
  return(mean_values)
}

#######
##cor##
#######

# Apply the function to pint dataset
cons_pint_l <- process_boots_data(df.boot_pint_l)
cons_pint_m <- process_boots_data(df.boot_pint_m)
cons_pint_h <- process_boots_data(df.boot_pint_h)

# Apply the function to pint 2_1 dataset
cons_pint_l_2_1 <- process_boots_data(df.boot_pint_l_2_1)
cons_pint_h_2_1 <- process_boots_data(df.boot_pint_h_2_1)

# Apply the function to pint 2_2 dataset
cons_pint_l_2_2 <- process_boots_data(df.boot_pint_l_2_2)
cons_pint_h_2_2 <- process_boots_data(df.boot_pint_h_2_2)

# Apply the function to educ dataset
cons_educ_l <- process_boots_data(df.boot_educ_l)
cons_educ_h <- process_boots_data(df.boot_educ_h)

########
##pcor##
########

# Apply the function to pint dataset
cons_pint_l_pc <- process_boots_data(df.boot_pint_l_pc)
cons_pint_m_pc <- process_boots_data(df.boot_pint_m_pc)
cons_pint_h_pc <- process_boots_data(df.boot_pint_h_pc)

# Apply the function to pint 2_1 dataset
cons_pint_l_2_1_pc <- process_boots_data(df.boot_pint_l_2_1_pc)
cons_pint_h_2_1_pc <- process_boots_data(df.boot_pint_h_2_1_pc)  

# Apply the function to pint 2_2 dataset
cons_pint_l_2_2_pc <- process_boots_data(df.boot_pint_l_2_2_pc)
cons_pint_h_2_2_pc <- process_boots_data(df.boot_pint_h_2_2_pc)  

# Apply the function to educ dataset
cons_educ_l_pc <- process_boots_data(df.boot_educ_l_pc)
cons_educ_h_pc <- process_boots_data(df.boot_educ_h_pc)
```


## H1 and H2 

### Multiplot

```{r}
# Figure_1 (cor vs mgm)
img1 <- image_read(here("Output", "Supplement", "att.jpg"))
img2 <- image_read(here("Output", "Supplement", "att_mgm.jpg"))
combined_img <- image_append(c(img1, img2), stack = FALSE)
image_write(combined_img, path = here("Output", "Article", "Figure_1.jpg"))


```


### Violins

```{r}
# Function to create and print plots with custom colors for Correlational network and mgm
create_plot <- function(df_l, df_m = NULL, df_h, df_l_pc, df_m_pc = NULL, df_h_pc, x_axis_label) {
  # Create vectors for pint (if applicable) or education
  if (!is.null(df_m)) {
    pint <- c(rep("Low", 10000), rep("Medium", 10000), rep("High", 10000))
    pint <- factor(pint, levels = c("Low", "Medium", "High"))
    
    # Combine the cons_pint and cons_pint_pc data into one data frame
    const_val <- c(df_l, df_m, df_h, df_l_pc, df_m_pc, df_h_pc)
    data_type <- rep(c("Correlational network", "mgm"), each = 30000)
    pint_vector <- rep(pint, 2)  # Repeat pint vector twice for Correlational network and mgm

  } else {
    pint <- c(rep("Low", 10000), rep("High", 10000))
    pint <- factor(pint, levels = c("Low", "High"))
    
    # Combine the cons_pint and cons_pint_pc data into one data frame (only low and high)
    const_val <- c(df_l, df_h, df_l_pc, df_h_pc)
    data_type <- rep(c("Correlational network", "mgm"), each = 20000)
    pint_vector <- rep(pint, 2)  # Repeat pint vector twice for Correlational network and mgm
  }

  mcon_data <- data.frame(
    const_val = const_val,
    pint = pint_vector,
    data_type = data_type
  )

  # Calculate quantile-based confidence intervals (90% CI)
  mcon_data_summary <- mcon_data %>%
    group_by(pint, data_type) %>%
    summarise(
      m = mean(const_val),
      ymin = quantile(const_val, 0.025),  # 2.5 percentile
      ymax = quantile(const_val, 0.975)   # 97.5 percentile
    )

  # Create the faceted plot with different y-axis scales and custom colors
  plot <- ggplot() +
    geom_violin(data = mcon_data, aes(x = pint, y = const_val, fill = data_type), 
                scale = "count", width = 0.6) +  # Map fill to data_type
    geom_errorbar(data = mcon_data_summary, aes(x = pint, ymin = ymin, ymax = ymax), 
                  width = 0.2, linewidth = 0.7, color = "black") +
    ylab("Average Tightness") +
    xlab(x_axis_label) +  # Set the dynamic x-axis label here
    facet_wrap(~data_type, scales = "free_y") +  # Allow different y-axis scales
    scale_fill_manual(values = c("Correlational network" = "#966FD6B3", "mgm" = "#008B8BB3")) +  # Custom colors
    theme(axis.title.x = element_text(), legend.position = "none")
  
  # Print the plot
  print(plot)
}

# Create and print the H1_pint plot (with three levels)
H1 = create_plot(cons_pint_l, cons_pint_m, cons_pint_h, cons_pint_l_pc, cons_pint_m_pc, cons_pint_h_pc, "Political Interest")

# Create and print the H1_pint_2_1 plot (with two levels)
H1_2_1 = create_plot(cons_pint_l_2_1, NULL, cons_pint_h_2_1, cons_pint_l_2_1_pc, NULL, cons_pint_h_2_1_pc, "Political Interest - Option 1")

# Create and print the H1_pint_2_2 plot (with two levels)
H1_2_2 = create_plot(cons_pint_l_2_2, NULL, cons_pint_h_2_2, cons_pint_l_2_2_pc, NULL, cons_pint_h_2_2_pc, "Political Interest - Option 2")

# Create and print the H2_educ plot (with two levels and x-axis label "Education")
H2 = create_plot(cons_educ_l, NULL, cons_educ_h, cons_educ_l_pc, NULL, cons_educ_h_pc, "Education")

```

```{r}
# Figure_2 multiplot
Figure_2 = H1 / H2

ggsave(here("Output", "Article", "Figure_2.jpg"), Figure_2, width = 12, height = 8, dpi = 300)

# Fig_3 multiplot
Fig_3 = H1_2_1 / H1_2_2

ggsave(here("Output", "Supplement", "Fig_3.jpg"), Fig_3, width = 12, height = 8, dpi = 300)
```

### R2

```{r}
# Initialize an empty list to store predictions
pred_list <- list()

# Loop through datasets and store R2 values
for (name in names(datasets)) {
  # Fit MGM and get R2 predictions
  data_matrix <- prepare_matrix_data(datasets[[name]])
  mgm_model <- mgm(data_matrix, type = rep("g", length(shortnames)), 
                   level = rep(1, length(shortnames)), lambdaSel = "EBIC", ruleReg = "OR")
  pred_mgm <- predict(object = mgm_model, data = data_matrix, errorCon = 'R2')
  
  # Store the R2 values with the variable names
  pred_list[[name]] <- tibble(Variable = pred_mgm$errors[, 1], 
                              R2 = pred_mgm$errors[, 2], 
                              group = name)
}

# Combine all predictions into a single data frame
pred_df <- bind_rows(pred_list) %>%
  pivot_wider(names_from = group, values_from = R2)

# Save prediction table to Word file
sjPlot::tab_df(pred_df, file = here("Output", "Supplement", "Tab_2.doc"))

# Summarize the difference in R2 values between groups
sum_pred_df <- tibble(
  sum_educ = sum(pred_df$educ_high) - sum(pred_df$educ_low),
  sum_pint = sum(pred_df$pol_int_high) - sum(pred_df$pol_int_low)
)

# Reshape the data without including 'att' group
plot_data <- pred_df %>%
  pivot_longer(cols = -Variable, names_to = "group", values_to = "value") %>%
  filter(!str_detect(group, "att")) %>%
  mutate(
    type = case_when(
      str_detect(group, "educ") ~ "educ",
      str_detect(group, "pol_int") ~ "pint",
      TRUE ~ NA_character_
    ),
    group = case_when(
      str_detect(group, "_low") ~ "low",
      str_detect(group, "_high") ~ "high",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(group))  # Remove rows with NA in group

# Plot function
create_plot_2 <- function(data, type) {
  data_wide <- data %>%
    pivot_wider(names_from = group, values_from = value) %>%
    arrange(desc(high)) %>%
    mutate(Variable = factor(Variable, levels = unique(Variable)))
  
  ggplot(data_wide) +
    geom_segment(aes(x = Variable, xend = Variable, y = low, yend = high), color = "grey") +
    geom_point(aes(x = Variable, y = low, color = "Low Group"), size = 3) +
    geom_point(aes(x = Variable, y = high, color = "High Group"), size = 3) +
    coord_flip() +
    scale_color_manual(values = c("Low Group" = "#966FD6B3", "High Group" = "#008B8BB3")) + 
    theme_ipsum() +
    theme(
      legend.position = "none",  # Suppress the legend
      axis.title.y = element_text(size = 14, face = "bold"),
      plot.title = element_text(hjust = 0.5),
      legend.title = element_text(size = 12, face = "bold")
    ) +
    xlab("") +
    ylab("R2") +
    labs(
      title = paste(type)
    )
}

# Generate plots
plot_educ_r2 <- create_plot_2(plot_data %>% filter(type == "educ"), "Education")
plot_pint_r2 <- create_plot_2(plot_data %>% filter(type == "pint"), "Political Interest")

# Summarize data for the bar plot
sum_data <- plot_data %>%
  group_by(type, group) %>%
  summarise(total_value = mean(value, na.rm = TRUE)) %>%
  ungroup()

# Create the bar plot
sum_plot <- ggplot(sum_data, aes(fill = group, y = total_value, x = type)) + 
  geom_bar(position = position_dodge(width = 0.9), stat = "identity") +
  scale_fill_manual(values = c("low" = "#966FD6B3", "high" = "#008B8BB3")) +
  labs(title = "Mean R2 by group", y = "Mean R2", fill = "Group", x = NULL) +  # Remove the x-axis label "type"
  coord_flip() +
  scale_x_discrete(labels = c("pint" = "Political interest", "educ" = "Education")) +  # Change axis labels
  theme_ipsum() +
  theme(
    plot.title = element_text(hjust = 0.5),  
    legend.position = "bottom",  
    panel.border = element_blank())

# Save
Figure_3 <- (plot_pint_r2 + plot_educ_r2) / sum_plot + 
  plot_layout(heights = c(4, 1))

ggsave(here("Output", "Article", "Figure_3.png"), Figure_3, width = 12, height = 8, dpi = 300)
```

### Moderations

```{r}
# Data prep
mnm_educ_data = IPBS %>% 
  select(L_R: ukrai, educ_cat) %>% 
  mutate(educ_cat = case_when(
    educ_cat == "Degree or more" ~ 1,
    educ_cat == "Less than university" ~ 0)) %>% 
  as.matrix()

mnm_pint_data = IPBS %>% 
  select(L_R: ukrai, pol_int) %>% 
  mutate(pol_int = case_when(
    pol_int %in% c(1,2) ~ 0,
    pol_int %in% c(3,4) ~ 1
  )) %>% 
  as.matrix()

# mnms
mnm_educ = mgm(mnm_educ_data, type = c(rep("g", 19), "c"), level = c(rep(1, 19), 2),
               moderators = 20, lambdaSel = "EBIC", ruleReg = "OR", binarySign = T)

mnm_pint = mgm(mnm_pint_data, type = c(rep("g", 19), "c"), level = c(rep(1, 19), 2),
               moderators = 20, lambdaSel = "EBIC", ruleReg = "OR", binarySign = T)

# Inspecting interactions
mnm_pint$interactions$indicator #61 pairwise, 23 moderations
mnm_educ$interactions$indicator #72 pairwise, 9 moderations
```


```{r}
# Multiplot

# conditioning on the moderator
educ_l_cond <- condition(mnm_educ, values = list("20" = 0))
educ_h_cond <- condition(mnm_educ, values = list("20" = 1))

pint_l_cond <- condition(mnm_pint, values = list("20" = 0))
pint_h_cond <- condition(mnm_pint, values = list("20" = 1))
```


```{r}
# Graph moderation coefficient

if (fast_running==0) {
  
# bootstrap of moderation coefficients
res_educ <- resample(object = mnm_educ, data = mnm_educ_data, nB = 100)
res_pint <- resample(object = mnm_pint, data = mnm_pint_data, nB = 100)

#Save Bootnets
save(res_educ, file = here("Input", "Boots", "boots_mnm_educ.RData"))
save(res_pint, file = here("Input", "Boots", "boots_mnm_pint.RData"))

} else {
  
  #Boots
load(file = here("Input", "Boots", "boots_mnm_educ.RData"))
load(file = here("Input", "Boots", "boots_mnm_pint.RData"))

}

# Load the variable names from your datasets
names_educ <- colnames(mnm_educ_data)
names_pint <- colnames(mnm_pint_data)

# Generate the dataframe for the education resample
tab_mod_educ = data.frame(plotRes(res_educ, 
                                  axis.ticks = c(-.1, 0, .1, .2, .3, .4, .5), 
                                  axis.ticks.mod = c(-.1, -.05, 0, .05, .1), 
                                  cex.label = 1, 
                                  decreasing = TRUE,
                                  labels = names_educ, 
                                  layout.width.labels = 1,
                                  table = TRUE))

# Generate the dataframe for the political interest resample
tab_mod_pint = data.frame(plotRes(res_pint, 
                                  axis.ticks = c(-.1, 0, .1, .2, .3, .4, .5), 
                                  axis.ticks.mod = c(-.1, -.05, 0, .05, .1), 
                                  cex.label = 1, 
                                  decreasing = TRUE,
                                  labels = names_pint, 
                                  layout.width.labels = 1,
                                  table = TRUE))

# Filter and arrange the education dataframe similar to tab_mod_df
tab_mod_df_educ = tab_mod_educ %>%
  select(Variable.A, Variable.B, Mod_Mean, Mod_qtl_low, Mod_qtl_high, Mod_propLtZ) %>% 
  filter(Mod_propLtZ > 0.40) %>%  # Filter for moderation effect detected in more than 80% of bootstrap samples
  arrange(desc(Mod_Mean))

# Filter and arrange the political interest dataframe similar to tab_mod_df
tab_mod_df_pint = tab_mod_pint %>%
  select(Variable.A, Variable.B, Mod_Mean, Mod_qtl_low, Mod_qtl_high, Mod_propLtZ) %>% 
  filter(Mod_propLtZ > 0.40) %>%  # Filter for moderation effect detected in more than 80% of bootstrap samples
  arrange(desc(Mod_Mean))

# Replace numeric values with corresponding variable names in education dataframe
tab_mod_df_educ$Variable.A <- ifelse(tab_mod_df_educ$Variable.A >= 1 & tab_mod_df_educ$Variable.A <= length(names_educ),
                                     names_educ[tab_mod_df_educ$Variable.A],
                                     tab_mod_df_educ$Variable.A)

tab_mod_df_educ$Variable.B <- ifelse(tab_mod_df_educ$Variable.B >= 1 & tab_mod_df_educ$Variable.B <= length(names_educ),
                                     names_educ[tab_mod_df_educ$Variable.B],
                                     tab_mod_df_educ$Variable.B)

# Replace numeric values with corresponding variable names in political interest dataframe
tab_mod_df_pint$Variable.A <- ifelse(tab_mod_df_pint$Variable.A >= 1 & tab_mod_df_pint$Variable.A <= length(names_pint),
                                     names_pint[tab_mod_df_pint$Variable.A],
                                     tab_mod_df_pint$Variable.A)

tab_mod_df_pint$Variable.B <- ifelse(tab_mod_df_pint$Variable.B >= 1 & tab_mod_df_pint$Variable.B <= length(names_pint),
                                     names_pint[tab_mod_df_pint$Variable.B],
                                     tab_mod_df_pint$Variable.B)

```

## H3

### mnm plot

```{r}
#Enlarge objects
shortnames = c("L_R","PTV_PD","PTV_FI","PTV_L","PTV_M5S","PTV_FDI","adopt","abort","eutha","marria","redis","flat_t","m_wage","cit_in","globa",     
                "immig","big_go","pub_pri","ukrai","vote_cat")

Totalgroup_comm <- list(
  "Symbolic" = c(1:6),
  "Operational" = c(7:19),
  "Vote choice" = c(20)
)

Totalgroup_cols <- c("#966FD6B3", "#008B8BB3", "#FFFF00")  

# Data prep
mnm_vote_data <- IPBS %>% 
  select(L_R:ukrai, vote_cat) %>% 
  mutate(vote_cat = case_when(
    vote_cat == "Sin" ~ 1,
    vote_cat == "M5S" ~ 2,  # This group will be ignored in the plotting
    vote_cat == "Dx" ~ 3
  )) %>% 
  na.omit() %>% 
  as.matrix()

# Fit the mgm model
mnm_vote <- mgm(
  data = mnm_vote_data,
  type = c(rep("g", 19), "c"),  
  level = c(rep(1, 19), 3),     
  moderators = 20,              
  lambdaSel = "EBIC",           
  ruleReg = "OR"                
)

# Conditioning the model on each level of vote_cat (Left and Right only)
cond1 <- condition(object = mnm_vote, values = list('20' = 1))  # Left (Sin)
cond3 <- condition(object = mnm_vote, values = list('20' = 3))  # Right (Dx)

# Initial plots to generate layouts
Graph_cond_1 <- qgraph(cond1$pairwise$wadj)
Graph_cond_3 <- qgraph(cond3$pairwise$wadj)

# Multiplot for Left and Right only
jpeg(here("Output", "Article", "mnm_vote_left_right.jpg"), 
     height = 4000, width = 8000, quality = 1000)  # Adjust image size as needed

# Create a common layout based on the two conditions
L <- averageLayout(Graph_cond_1, Graph_cond_3, layout = "spring")

# Matrix layout for the graphs (1 row, 2 columns)
lmat <- matrix(1:2, 1, 2)

# Start plotting
layout(lmat, width = c(1, 1))

# Generate plots for Left (Sin)
set.seed(1)
Graph_cond_1 <- qgraph(
  cond1$pairwise$wadj, layout = L, fade = TRUE,  # Enable edge fading
  labels = shortnames, vTrans = 255,  # Transparency setting
  groups = Totalgroup_comm,  
  color = Totalgroup_cols,  
  legend = FALSE, title = "Left", title.cex = 12,
  edge.color = cond1$pairwise$edgecolor_cb,  # Ensure edge colors reflect the weights
  borders = TRUE, vsize = 10, esize = 15, 
  edge.alpha = TRUE,  # Use edge.alpha to control transparency based on edge weight
  cut = 0.05,  # Set a lower cut-off threshold
  alpha = 0.7,  # Explicit alpha control to help edge fading
  maximum = max(c(cond1$pairwise$wadj, cond3$pairwise$wadj))  # Consistent scaling across plots
)

# Generate plots for Right (Dx)
set.seed(1)
Graph_cond_3 <- qgraph(
  cond3$pairwise$wadj, layout = L, fade = TRUE,  # Enable edge fading
  labels = shortnames,  
  groups = Totalgroup_comm, 
  color = Totalgroup_cols, 
  legend = FALSE, title = "Right", title.cex = 12,
  edge.color = cond3$pairwise$edgecolor_cb,  # Ensure edge colors reflect the weights
  borders = TRUE, vsize = 10, esize = 15, 
  edge.alpha = TRUE,  # Use edge.alpha to control transparency based on edge weight
  cut = 0.05,  # Set a lower cut-off threshold
  alpha = 0.7,  # Explicit alpha control to help edge fading
  maximum = max(c(cond1$pairwise$wadj, cond3$pairwise$wadj))  # Consistent scaling across plots
)

# Finish and save the plot
dev.off()

```

### coef moderation

```{r}
# Check if we need to resample or load the results
if (fast_running == 0) {
  
  # Bootstrap moderation coefficients for mnm_vote model
  res_vote <- resample(object = mnm_vote, data = mnm_vote_data, nB = 1000)
  
  # Save Bootnets
  save(res_vote, file = here("Input", "Boots", "boots_mnm_vote.RData"))
  
} else {
  
  # Load the resampled models
  load(file = here("Input", "Boots", "boots_mnm_vote.RData"))
}

# Load the variable names from your mnm_vote_data
names_vote <- shortnames

# Generate the dataframe for the resample of mnm_vote
tab_mod_vote <- data.frame(plotRes(res_vote, 
                                  axis.ticks = c(-.1, 0, .1, .2, .3, .4, .5), 
                                  axis.ticks.mod = c(-.1, -.05, 0, .05, .1), 
                                  cex.label = 1, 
                                  decreasing = TRUE,
                                  labels = names_vote, 
                                  layout.width.labels = 1,
                                  table = TRUE))

# Filter and arrange the vote dataframe similar to tab_mod_df
tab_mod_df_vote <- tab_mod_vote %>%
  select(Variable.A, Variable.B, Mod_Mean, Mod_qtl_low, Mod_qtl_high, Mod_propLtZ) %>% 
  filter(Mod_propLtZ > 0.40) %>%  # Filter for moderation effect detected in more than 40% of bootstrap samples
  arrange(desc(Mod_Mean))

# Replace numeric values with corresponding variable names in vote dataframe
tab_mod_df_vote$Variable.A <- ifelse(tab_mod_df_vote$Variable.A >= 1 & tab_mod_df_vote$Variable.A <= length(names_vote),
                                     names_vote[tab_mod_df_vote$Variable.A],
                                     tab_mod_df_vote$Variable.A)

tab_mod_df_vote$Variable.B <- ifelse(tab_mod_df_vote$Variable.B >= 1 & tab_mod_df_vote$Variable.B <= length(names_vote),
                                     names_vote[tab_mod_df_vote$Variable.B],
                                     tab_mod_df_vote$Variable.B)

# Save the result to CSV
write.csv(tab_mod_df_vote, here("Output", "Supplement", "tab_mod_df_vote.csv"), row.names = FALSE)

# Print the final table
print(tab_mod_df_vote)

```

# OLD

# Network descriptives
This code replicates descriptives of the networks used throughout the article

```{r}
#Figure 1

## Min edge weight
min_fig1 = att_net %>% 
  as.vector() %>%
  min()

## Max edge weight
max_fig1 = att_net %>% 
  as.vector() 
max_fig1 = max_fig1[max_fig1 != 1]
max_fig1 = max_fig1 %>%
 max()


## Node strength
strength_fig1 = centrality(att_net)
min_st_fig1 = min(strength_fig1$OutDegree)
max_st_fig1 = max(strength_fig1$OutDegree)

## Constraint
const_fig1 = mean(att_net)

## N° of zero cells
zerofig1 = sum(att_net <= 0.001)

## N° of non zero edges
nonzerofig1 = sum(att_net != 0)
```

```{r}
#Figure 2

## Point estimate and ci of each subgroup
mcon_pint_summary
mcon_edu_summary
```

```{r}
#Figure 3

## N° of non zero edges
n_left = (sum(vote_l_data_net != 0))/2
n_mov = (sum(vote_m_data_net != 0))/2
n_right = (sum(vote_r_data_net != 0))/2


## Density of each plot (Sum of the Absolute Value of Each Cell of a Matrix)
d_left = sum(abs(vote_l_data_net))
d_mov = sum(abs(vote_m_data_net))
d_right = sum(abs(vote_r_data_net))

```

```{r}
#NCT

## N° edges differing between each network pair
nnct_rm =  sum(input_NCTgraph_r_m != 0)
nnct_lr =  sum(input_NCTgraph_l_r != 0)
nnct_lm =  sum(input_NCTgraph_l_m != 0)

max_rm = max(input_NCTgraph_r_m)
max_lr = max(input_NCTgraph_l_r)
max_lm =  max(input_NCTgraph_l_m)
```

```{r}
#Figure 4

## average value of absolute edge weight in each vote bel syst (NON 0)
#left
avg_edg_l = vote_l_data_net %>% 
  abs() %>% 
  as.vector()

avg_edg_l = avg_edg_l[avg_edg_l != 0]
avg_edg_l = avg_edg_l[avg_edg_l != 1]

avg_edg_l = mean(avg_edg_l)

#right
avg_edg_m = vote_m_data_net %>% 
  abs() %>% 
  as.vector()

avg_edg_m = avg_edg_m[avg_edg_m != 0]
avg_edg_m = avg_edg_m[avg_edg_m != 1]

avg_edg_m = mean(avg_edg_m)

#Mov
avg_edg_r = vote_r_data_net %>% 
  abs() %>% 
  as.vector()

avg_edg_r = avg_edg_r[avg_edg_r != 0]
avg_edg_r = avg_edg_r[avg_edg_r != 1]

avg_edg_r = mean(avg_edg_r)

# Number of edges differing between matrices
ndiff_rm = (sum(vote_r_data_net != vote_m_data_net))/2
ndiff_lr = (sum(vote_l_data_net != vote_r_data_net))/2
ndiff_lm = (sum(vote_l_data_net != vote_m_data_net))/2

#theorethical max n of edges 
tmax = 19*18/2
```


