---
title: "3_IPBS_mgm_230912"
author: "Arturo Bertero"
date: "2023-09-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(pacman)
p_load(tidyverse, here, sjlabelled, stringr, glue, EGAnet, janitor, haven,
       ggpubr, gridExtra, dplyr, GGally, qgraph, sjmisc, igraph,
       sjPlot, sna, grid, psych, stargazer, mgm, backbone, ggplot2, tnet,
       ggrepel, EGAnet, NetworkComparisonTest, Matrix, bootnet, matrixcalc, 
       openxlsx, devtools, jtools, corrr, patchwork, magick, hrbrthemes)

options(scipen=999)
```

# Input

```{r}
#Load data
IPBS = readRDS((here("Input", "IPBS.rds")))

#Filter smaller dataset
att = IPBS %>% 
  dplyr::select(c(L_R:ukrai)) 

#Partitions
load(file = here("Input", "Partitions", "pol_int_partitions.RData"))
load(file = here("Input", "Partitions", "pol_int_partitions_2_1.RData"))
load(file = here("Input", "Partitions", "pol_int_partitions_2_2.RData"))
load(file = here("Input", "Partitions", "educ_partitions.RData"))
load(file = here("Input", "Partitions", "vote_partitions.RData"))

#Fast running (run [0] or skip [1] bootnet and NCT)
fast_running = 1
```

# Processing

##  Cor network estimation 

```{r}
# Define shortnames, longnames, and groupings as per your original code
shortnames <- names(att)
longnames <- c("Left right","Propensity to vote for PD",
               "Propensity to vote for FI","Propensity to vote for L",
               "Propensity to vote for M5S","Propensity to vote for FDI",
               "Step child adoption","Abortion","Euthanasia","Omosexual marriage",
               "Redistribution","Flat tax","Minimum wage","Citizenship income",
               "Globalization","Immigration","Big government",
               "Public vs private","Weapons to Ukraine")

Totalgroup_comm <- list(
  "Symbolic" = c(1:6),
  "Operational" = c(7:19)
)

Totalgroup_cols <- c("#eeeeee", "#adadad")  # Third color is omitted for now, could be added if needed.

```

```{r}
# estimation on att

#remove labels
att = sapply(att, haven::zap_labels)

#declare operational or symbolic
nature = c(rep("Symbolic", 6),
            rep("Operational", 13))

#Fit cor network 
att_net = cor_auto(att, npn.SKEPTIC = T, #Nonparanormal transformation (HUGE)
                        ordinalLevelMax = 7, #from keskinturk
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE)

#square the matrix
att_net = att_net^2

#plot
qgraph(att_net,
         fade = FALSE, layout = "spring", theme = "gray", 
         labels = shortnames, nodeNames = longnames,
         vsize = 7.0, label.cex = 1.1, cut = 0.07,
         groups = Totalgroup_comm, color = Totalgroup_cols,
         legend = F, legend.cex = 0.40, title = "cor",
         filetype = "jpg", filename = here("Output", "Supplement", "att"))
```

```{r}
# Function to ensure input data is in matrix/data frame format
prepare_data <- function(data) {
  if (is.list(data)) {
    return(as.data.frame(do.call(cbind, data)))  # Convert list to data frame
  } else if (is.vector(data)) {
    return(as.data.frame(matrix(data, nrow = length(data))))  # Convert vector to a data frame
  } else {
    return(as.data.frame(data))  # Already in correct format
  }
}

# Function to fit and plot correlation networks and save the plots to a file
generate_network_plots <- function(low_data, high_data, shortnames, longnames, group_names, group_colors, title_low, title_high, file_base) {
  # Remove labels
  low_data <- sapply(low_data, haven::zap_labels)
  high_data <- sapply(high_data, haven::zap_labels)
  
  # Fit GGM for low data
  low_data_net <- cor_auto(low_data, npn.SKEPTIC = TRUE, ordinalLevelMax = 7, forcePD = TRUE, missing = "pairwise", verbose = FALSE)
  low_data_net <- low_data_net^2  # Square the matrix
  
  # Fit GGM for high data
  high_data_net <- cor_auto(high_data, npn.SKEPTIC = TRUE, ordinalLevelMax = 7, forcePD = TRUE, missing = "pairwise", verbose = FALSE)
  high_data_net <- high_data_net^2  # Square the matrix
  
  # Save plot for low data
  set.seed(1)
  qgraph(low_data_net,
         fade = FALSE, layout = "spring", theme = "gray", 
         labels = shortnames, nodeNames = longnames,
         vsize = 7.0, label.cex = 1.1, cut = 0.07,
         groups = group_names, color = group_colors,
         legend = F, legend.cex = 0.40, title = title_low,
         filetype = "jpg", filename = here("Output", "Supplement", paste0(file_base, "_Low")))
  
  # Save plot for high data
  set.seed(1)
  qgraph(high_data_net,
         fade = FALSE, layout = "spring", theme = "gray", 
         labels = shortnames, nodeNames = longnames,
         vsize = 7.0, label.cex = 1.1, cut = 0.07,
         groups = group_names, color = group_colors,
         legend = F, legend.cex = 0.40, title = title_high,
         filetype = "jpg", filename = here("Output", "Supplement", paste0(file_base, "_High")))
}

# Generate Political Interest plots and save them
generate_network_plots(
  low_data = prepare_data(polint_2_1_l),
  high_data = prepare_data(polint_2_1_h),
  shortnames = shortnames, 
  longnames = longnames,
  group_names = Totalgroup_comm, 
  group_colors = Totalgroup_cols, 
  title_low = "Political Interest - Low",
  title_high = "Political Interest - High",
  file_base = "Fig_Political_Interest"
)

# Generate Education plots and save them
generate_network_plots(
  low_data = prepare_data(educ_low),
  high_data = prepare_data(educ_high),
  shortnames = shortnames, 
  longnames = longnames,
  group_names = Totalgroup_comm, 
  group_colors = Totalgroup_cols, 
  title_low = "Education - Low",
  title_high = "Education - High",
  file_base = "Fig_Education"
)

```


## MGMs

```{r}
# Function to ensure input data is in matrix format
prepare_matrix_data <- function(data) {
  if (!is.matrix(data)) {
    return(as.matrix(data))  # Convert to matrix if it's not already
  }
  return(data)
}

# Function to fit MGM and plot the results
fit_and_plot_mgm <- function(data, shortnames, longnames, mgm_groups, mgm_colors, file_base) {
  # Prepare data as a matrix
  data_matrix <- prepare_matrix_data(data)
  
  # Fit MGM model (all continuous variables)
  mgm_model <- mgm(data_matrix, type = rep("g", length(shortnames)), 
                   level = rep(1, length(shortnames)), lambdaSel = "EBIC", ruleReg = "OR")
  
  # Predictability
  pred_mgm <- predict(object = mgm_model, data = data_matrix, errorCon = 'R2')
  
  # Plot the MGM network
  graph_mgm <- qgraph(mgm_model$pairwise$wadj, layout = 'spring',
                      labels = shortnames, nodeNames = longnames,  
                      groups = mgm_groups, color = mgm_colors, 
                      legend = T, legend.cex = 0.33, 
                      edge.color = mgm_model$pairwise$edgecolor_cb,
                      borders = T, vsize = 7.0, esize = 15, GLratio = 2,
                      pie = pred_mgm$errors[,2], pieColor = rep('#FFFF00', length(shortnames)),
                      filetype = "jpg",  
                      filename = here("Output", "Supplement", file_base))
}

# Fit and plot MGM for all datasets
datasets <- list(
  "att" = att,
  "pol_int_low" = polint_2_1_l,
  "pol_int_high" = polint_2_1_h,
  "educ_low" = educ_low,
  "educ_high" = educ_high
)

# Loop through datasets and apply MGM fitting and plotting
for (name in names(datasets)) {
  fit_and_plot_mgm(
    data = datasets[[name]],
    shortnames = shortnames, 
    longnames = longnames,
    mgm_groups = Totalgroup_comm, 
    mgm_colors = Totalgroup_cols, 
    file_base = paste0(name, "_mgm")
  )
}


```


## Bootstrap analyses (cor)

```{r}
if (fast_running==0) {

##############################
#Bootstrapped on full samples
##############################

#boots_att
boot_att = zap_labels(att) %>%
          data.frame()

df.boot_att = bootnet(boot_att, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)
#Save Bootnets
save(df.boot_att, file = here("Input", "Boots", "boots_att.RData"))

###############
#Bootstrap pint
###############

#low
polint_low_and_midlow = zap_labels(polint_low_and_midlow) %>%
          data.frame()
df.boot_pint_l <- bootnet(polint_low_and_midlow, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#mid
pol_int_midhigh = zap_labels(pol_int_midhigh) %>%
          data.frame()
df.boot_pint_m <- bootnet(pol_int_midhigh, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#high
pol_int_high = zap_labels(pol_int_high) %>%
          data.frame()
df.boot_pint_h <- bootnet(pol_int_high, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l,df.boot_pint_m,df.boot_pint_h,
     file = here("Input", "Boots", "boots_pint.RData"))

###############
#Bootstrap educ
###############

#low
educ_low = zap_labels(educ_low) %>%
          data.frame()
df.boot_educ_l <- bootnet(educ_low, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#high
educ_high = zap_labels(educ_high) %>%
          data.frame()
df.boot_educ_h <- bootnet(educ_high, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_educ_l,df.boot_educ_h,
     file = here("Input", "Boots", "boots_educ.RData"))

#################
#Additional pint#
#################

# On 2_1

#low
polint_l_2_1 = zap_labels(polint_2_1_l) %>%
          data.frame()
df.boot_pint_l_2_1 <- bootnet(polint_l_2_1, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#high
polint_h_2_1 = zap_labels(polint_2_1_h) %>%
          data.frame()
df.boot_pint_h_2_1 <- bootnet(polint_h_2_1, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l_2_1,df.boot_pint_h_2_1,
     file = here("Input", "Boots", "boots_pint_2_1.RData"))

# On 2_2

#low
polint_l_2_2 = zap_labels(polint_2_2_l) %>%
          data.frame()
df.boot_pint_l_2_2 <- bootnet(polint_l_2_2, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#high
polint_h_2_2 = zap_labels(polint_2_2_h) %>%
          data.frame()
df.boot_pint_h_2_2 <- bootnet(polint_h_2_2, nBoots = 10000, nCores = 8,
                     default = "cor", type = "nonparametric",
                     corMethod = "cor_auto", corArgs = list(
                        npn.SKEPTIC = T,
                        ordinalLevelMax = 7, 
                        forcePD = TRUE,
                        missing = "pairwise",
                        verbose = FALSE),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l_2_2,df.boot_pint_h_2_2,
     file = here("Input", "Boots", "boots_pint_2_2.RData"))

} else {
  
  #Boots
load(file = here("Input", "Boots", "boots_att.RData"))
load(file = here("Input", "Boots", "boots_pint.RData"))
load(file = here("Input", "Boots", "boots_educ.RData"))
load(file = here("Input", "Boots", "boots_pint_2_1.RData"))
load(file = here("Input", "Boots", "boots_pint_2_2.RData"))
}
```

## Bootstrap analyses (cor)

```{r}
if (fast_running==0) {

##############################
#Bootstrapped on full samples
##############################

#boots_att_pc
df.boot_att_pc <- bootnet(boot_att, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)
#Save Bootnets
save(df.boot_att_pc, file = here("Input", "Boots", "boots_att_pc.RData"))


###############
#Bootstrap pint
###############

#boots_pint_l_pc
df.boot_pint_l_pc <- bootnet(polint_low_and_midlow, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#boots_pint_m_pc
df.boot_pint_m_pc <- bootnet(pol_int_midhigh, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#boots_pint_h_pc
df.boot_pint_h_pc <- bootnet(pol_int_high, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)
#Save Bootnets 
save(df.boot_pint_l_pc,df.boot_pint_m_pc,df.boot_pint_h_pc,
     file = here("Input", "Boots", "boots_pint_pc.RData"))


###############
#Bootstrap educ
###############

#boots_educ_l_pc
df.boot_educ_l_pc <- bootnet(educ_low, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#boots_educ_h_pc
df.boot_educ_h_pc <- bootnet(educ_high, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_educ_l_pc,df.boot_educ_h_pc,
     file = here("Input", "Boots", "boots_educ_pc.RData"))



#################
#Additional pint#
#################

# On 2_1

#low
df.boot_pint_l_2_1_pc <- bootnet(polint_l_2_1, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#high
df.boot_pint_h_2_1_pc <- bootnet(polint_h_2_1, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l_2_1_pc,df.boot_pint_h_2_1_pc,
     file = here("Input", "Boots", "boots_pint_2_1_pc.RData"))

# On 2_2

#low
df.boot_pint_l_2_2_pc <- bootnet(polint_l_2_2, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#high
df.boot_pint_h_2_2_pc <- bootnet(polint_h_2_2, nBoots = 10000, nCores = 8,
                     default = "EBICglasso", statistics = c("edge"),
                        computeCentrality = FALSE)

#Save Bootnets
save(df.boot_pint_l_2_2_pc,df.boot_pint_h_2_2_pc,
     file = here("Input", "Boots", "boots_pint_2_2_pc.RData"))

} else {
  
  #Boots
load(file = here("Input", "Boots", "boots_att_pc.RData"))
load(file = here("Input", "Boots", "boots_pint_pc.RData"))
load(file = here("Input", "Boots", "boots_educ_pc.RData"))
load(file = here("Input", "Boots", "boots_pint_2_1_pc.RData"))
load(file = here("Input", "Boots", "boots_pint_2_2_pc.RData"))
}
```

## Extract info from boots

```{r}
# Function to process each dataset
process_boots_data <- function(df_boot) {
  # Extract the matrices
  matrix_list <- lapply(1:10000, function(i) {
    df_boot[["boots"]][[i]][["graph"]]
  })
  
  # Calculate the mean of the squared matrix for each matrix
  mean_values <- sapply(matrix_list, function(mat) {
    squared_matrix <- mat^2
    mean(squared_matrix)
  })
  
  return(mean_values)
}

#######
##cor##
#######

# Apply the function to pint dataset
cons_pint_l <- process_boots_data(df.boot_pint_l)
cons_pint_m <- process_boots_data(df.boot_pint_m)
cons_pint_h <- process_boots_data(df.boot_pint_h)

# Apply the function to pint 2_1 dataset
cons_pint_l_2_1 <- process_boots_data(df.boot_pint_l_2_1)
cons_pint_h_2_1 <- process_boots_data(df.boot_pint_h_2_1)

# Apply the function to pint 2_2 dataset
cons_pint_l_2_2 <- process_boots_data(df.boot_pint_l_2_2)
cons_pint_h_2_2 <- process_boots_data(df.boot_pint_h_2_2)

# Apply the function to educ dataset
cons_educ_l <- process_boots_data(df.boot_educ_l)
cons_educ_h <- process_boots_data(df.boot_educ_h)

########
##pcor##
########

# Apply the function to pint dataset
cons_pint_l_pc <- process_boots_data(df.boot_pint_l_pc)
cons_pint_m_pc <- process_boots_data(df.boot_pint_m_pc)
cons_pint_h_pc <- process_boots_data(df.boot_pint_h_pc)

# Apply the function to pint 2_1 dataset
cons_pint_l_2_1_pc <- process_boots_data(df.boot_pint_l_2_1_pc)
cons_pint_h_2_1_pc <- process_boots_data(df.boot_pint_h_2_1_pc)  

# Apply the function to pint 2_2 dataset
cons_pint_l_2_2_pc <- process_boots_data(df.boot_pint_l_2_2_pc)
cons_pint_h_2_2_pc <- process_boots_data(df.boot_pint_h_2_2_pc)  

# Apply the function to educ dataset
cons_educ_l_pc <- process_boots_data(df.boot_educ_l_pc)
cons_educ_h_pc <- process_boots_data(df.boot_educ_h_pc)
```


### H1 and H2 

#### Multiplot (cor vs mgm)

```{r}
# Figure_1
img1 <- image_read(here("Output", "Supplement", "att.jpg"))
img2 <- image_read(here("Output", "Supplement", "att_mgm.jpg"))
combined_img <- image_append(c(img1, img2), stack = FALSE)
image_write(combined_img, path = here("Output", "Article", "Figure_1.jpg"))


```


#### Violins

```{r}
# Function to create and print plots
create_plot <- function(df_l, df_m = NULL, df_h, df_l_pc, df_m_pc = NULL, df_h_pc, x_axis_label) {
  # Create vectors for pint (if applicable) or education
  if (!is.null(df_m)) {
    pint <- c(rep("Low", 10000), rep("Medium", 10000), rep("High", 10000))
    pint <- factor(pint, levels = c("Low", "Medium", "High"))
    
    # Combine the cons_pint and cons_pint_pc data into one data frame
    const_val <- c(df_l, df_m, df_h, df_l_pc, df_m_pc, df_h_pc)
    data_type <- rep(c("Correlation", "Partial Correlation"), each = 30000)
    pint_vector <- rep(pint, 2)  # Repeat pint vector twice for correlation and partial correlation

  } else {
    pint <- c(rep("Low", 10000), rep("High", 10000))
    pint <- factor(pint, levels = c("Low", "High"))
    
    # Combine the cons_pint and cons_pint_pc data into one data frame (only low and high)
    const_val <- c(df_l, df_h, df_l_pc, df_h_pc)
    data_type <- rep(c("Correlation", "Partial Correlation"), each = 20000)
    pint_vector <- rep(pint, 2)  # Repeat pint vector twice for correlation and partial correlation
  }

  mcon_data <- data.frame(
    const_val = const_val,
    pint = pint_vector,
    data_type = data_type
  )

  # Calculate quantile-based confidence intervals (90% CI)
  mcon_data_summary <- mcon_data %>%
    group_by(pint, data_type) %>%
    summarise(
      m = mean(const_val),
      ymin = quantile(const_val, 0.025),  # 2.5 percentile
      ymax = quantile(const_val, 0.975)   # 97.5 percentile
    )

  # Create the faceted plot with different y-axis scales
  plot <- ggplot() +
    geom_violin(data = mcon_data, aes(x = pint, y = const_val), 
                scale = "count", width = 0.6, fill = "#5b5b5b") +  # Neutral fill
    geom_errorbar(data = mcon_data_summary, aes(x = pint, ymin = ymin, ymax = ymax), 
                  width = 0.2, linewidth = 0.7, color = "black") +
    ylab("Average Tightness") +
    xlab(x_axis_label) +  # Set the dynamic x-axis label here
    facet_wrap(~data_type, scales = "free_y") +  # Allow different y-axis scales
    theme(axis.title.x = element_text(), legend.position = "none")
  
  # Print the plot
  print(plot)
}

# Create and print the H1_pint plot (with three levels)
H1 = create_plot(cons_pint_l, cons_pint_m, cons_pint_h, cons_pint_l_pc, cons_pint_m_pc, cons_pint_h_pc, "Political Interest")

# Create and print the H1_pint_2_1 plot (with two levels)
H1_2_1 = create_plot(cons_pint_l_2_1, NULL, cons_pint_h_2_1, cons_pint_l_2_1_pc, NULL, cons_pint_h_2_1_pc, "Political Interest - Option 1")

# Create and print the H1_pint_2_2 plot (with two levels)
H1_2_2 = create_plot(cons_pint_l_2_2, NULL, cons_pint_h_2_2, cons_pint_l_2_2_pc, NULL, cons_pint_h_2_2_pc, "Political Interest - Option 2")

# Create and print the H2_educ plot (with two levels and x-axis label "Education")
H2 = create_plot(cons_educ_l, NULL, cons_educ_h, cons_educ_l_pc, NULL, cons_educ_h_pc, "Education")

```

```{r}
# Figure_2 multiplot
Figure_2 = H1 / H2

ggsave(here("Output", "Article", "Figure_2.jpg"), Figure_2, width = 12, height = 8, dpi = 300)

# Fig_3 multiplot
Fig_3 = H1_2_1 / H1_2_2

ggsave(here("Output", "Supplement", "Fig_3.jpg"), Fig_3, width = 12, height = 8, dpi = 300)
```

#### R2

```{r}
# Initialize an empty list to store predictions
pred_list <- list()

# Loop through datasets and store R2 values
for (name in names(datasets)) {
  # Fit MGM and get R2 predictions
  data_matrix <- prepare_matrix_data(datasets[[name]])
  mgm_model <- mgm(data_matrix, type = rep("g", length(shortnames)), 
                   level = rep(1, length(shortnames)), lambdaSel = "EBIC", ruleReg = "OR")
  pred_mgm <- predict(object = mgm_model, data = data_matrix, errorCon = 'R2')
  
  # Store the R2 values with the variable names
  pred_list[[name]] <- tibble(Variable = pred_mgm$errors[, 1], 
                              R2 = pred_mgm$errors[, 2], 
                              group = name)
}

# Combine all predictions into a single data frame
pred_df <- bind_rows(pred_list) %>%
  pivot_wider(names_from = group, values_from = R2)

# Save prediction table to Word file
sjPlot::tab_df(pred_df, file = here("Output", "Supplement", "Tab_2.doc"))

# Summarize the difference in R2 values between groups
sum_pred_df <- tibble(
  sum_educ = sum(pred_df$educ_high) - sum(pred_df$educ_low),
  sum_pint = sum(pred_df$pol_int_high) - sum(pred_df$pol_int_low)
)

# Reshape the data without including 'att' group
plot_data <- pred_df %>%
  pivot_longer(cols = -Variable, names_to = "group", values_to = "value") %>%
  filter(!str_detect(group, "att")) %>%
  mutate(
    type = case_when(
      str_detect(group, "educ") ~ "educ",
      str_detect(group, "pol_int") ~ "pint",
      TRUE ~ NA_character_
    ),
    group = case_when(
      str_detect(group, "_low") ~ "low",
      str_detect(group, "_high") ~ "high",
      TRUE ~ NA_character_
    )
  ) %>%
  filter(!is.na(group))  # Remove rows with NA in group

# Plot function
create_plot_2 <- function(data, type) {
  data_wide <- data %>%
    pivot_wider(names_from = group, values_from = value) %>%
    arrange(desc(high)) %>%
    mutate(Variable = factor(Variable, levels = unique(Variable)))
  
  ggplot(data_wide) +
    geom_segment(aes(x = Variable, xend = Variable, y = low, yend = high), color = "grey") +
    geom_point(aes(x = Variable, y = low, color = "Low Group"), size = 3) +
    geom_point(aes(x = Variable, y = high, color = "High Group"), size = 3) +
    coord_flip() +
    scale_color_manual(values = c("Low Group" = "#966FD6B3", "High Group" = "#008B8BB3")) + 
    theme_ipsum() +
    theme(
      legend.position = "bottom",
      axis.title.y = element_text(size = 14, face = "bold"),
      plot.title = element_text(hjust = 0.5),
      legend.title = element_text(size = 12, face = "bold")
    ) +
    xlab("") +
    ylab("R2") +
    labs(
      title = paste(type),
      color = "Group"
    )
}

# Generate plots
plot_educ_r2 <- create_plot_2(plot_data %>% filter(type == "educ"), "Education")
plot_pint_r2 <- create_plot_2(plot_data %>% filter(type == "pint"), "Political Interest")

# Summarize data for the bar plot
sum_data <- plot_data %>%
  group_by(type, group) %>%
  summarise(total_value = mean(value, na.rm = TRUE)) %>%
  ungroup()

# Create the bar plot
sum_plot = ggplot(sum_data, aes(fill = group, y = total_value, x = type)) + 
  geom_bar(position = position_dodge(width = 0.9), stat = "identity") +
  scale_fill_manual(values = c("low" = "#966FD6B3", "high" = "#008B8BB3")) +
  labs(title = "Mean R2 by group", y = "Mean R2", fill = "Group")


# Save
Figure_3 = plot_pint_r2 + sum_plot + plot_educ_r2
ggsave(here("Output", "Article", "Figure_3.png"), Figure_3, width = 12, height = 8, dpi = 300)
```



# OLD

## NCT analyses (OLD)
```{r}
if (fast_running==0) {

#Right versus Movement
NCT_r_m <- NCT(vote_right,vote_M5S, it = 10000,
                test.edges = TRUE, edges = "all", 
                test.centrality = FALSE)
#Save 
save(NCT_r_m, file = here("Input", "NCT", "NCT_r_m.RData"))

#Left vs Right
NCT_l_r <- NCT(vote_left,vote_right, it = 10000,
                test.edges = TRUE, edges = "all", 
                test.centrality = FALSE)
#Save 
save(NCT_l_r, file = here("Input", "NCT", "NCT_l_r.RData"))

#Left vs Movement
NCT_l_m <- NCT(vote_left,vote_M5S, it = 10000,
                test.edges = TRUE, edges = "all", 
                test.centrality = FALSE)
#Save 
save(NCT_l_m, file = here("Input", "NCT", "NCT_l_m.RData"))

} else {
  
  #Boots
load(file = here("Input", "NCT", "NCT_r_m.RData"))
load(file = here("Input", "NCT", "NCT_l_r.RData"))
load(file = here("Input", "NCT", "NCT_l_m.RData"))
}
```

### H3 heterogeneity hypothesis
(from 3 - mgm_230912.RMD (old folder of old GGM proj))

```{r}
#Visualize results of edge tests 

#r_m
input_NCTgraph_r_m <- vote_r_data_net - vote_m_data_net
input_NCTgraph_r_m[upper.tri(input_NCTgraph_r_m)][which(NCT_r_m$einv.pvals$`p-value` >= .05)] <- 0
input_NCTgraph_r_m <- forceSymmetric(input_NCTgraph_r_m)

nct_r_m = qgraph(input_NCTgraph_r_m, edge.labels = TRUE,
                  layout = "spring", theme = "Borkulo", 
                  labels = shortnames, nodeNames = longnames,
                  groups=Totalgroup_comm, color= Totalgroup_cols,
                  cut = 0.10, maximum = 1, 
                  details = FALSE, vsize=6.0, 
                  legend = FALSE, legend.cex = 0.35, borders = TRUE)

#l_r
input_NCTgraph_l_r <- vote_l_data_net - vote_r_data_net
input_NCTgraph_l_r[upper.tri(input_NCTgraph_l_r)][which(NCT_l_r$einv.pvals$`p-value` >= .05)] <- 0
input_NCTgraph_l_r <- forceSymmetric(input_NCTgraph_l_r)

nct_l_r = qgraph(input_NCTgraph_l_r, edge.labels = TRUE,
                  layout = "spring", theme = "Borkulo", 
                  labels = shortnames, nodeNames = longnames,
                  groups=Totalgroup_comm, color= Totalgroup_cols,
                  cut = 0.10, maximum = 1, 
                  details = FALSE, vsize=6.0, 
                  legend = FALSE, legend.cex = 0.35, borders = TRUE)

#l_m 
input_NCTgraph_l_m <- vote_l_data_net - vote_m_data_net
input_NCTgraph_l_m[upper.tri(input_NCTgraph_l_m)][which(NCT_l_m$einv.pvals$`p-value` >= .05)] <- 0
input_NCTgraph_l_m <- forceSymmetric(input_NCTgraph_l_m)

nct_l_m = qgraph(input_NCTgraph_l_m, edge.labels = TRUE,
                  layout = "spring", theme = "Borkulo", 
                  labels = shortnames, nodeNames = longnames,
                  groups=Totalgroup_comm, color= Totalgroup_cols,
                  cut = 0.10, maximum = 1, 
                  details = FALSE, vsize=6.0, 
                  legend = FALSE, legend.cex = 0.35, borders = TRUE)
```

```{r}
#Supplement multiplot
jpeg(here("Output", "Supplement", "Fig_4.jpg"), 
    height = 700, width = 1400, quality = 100)

L<-averageLayout(nct_l_m, nct_l_r, nct_r_m, layout = "spring")
lmat <- matrix(1:3, 1)
lo <- layout(lmat, width = c(1, 1))

set.seed(1)
nct_r_m = qgraph(input_NCTgraph_r_m, edge.labels = TRUE,
                  layout = L, theme = "Borkulo", title = "Right - 5SM",
                  title.cex = 3, labels = shortnames, nodeNames = longnames,
                  groups=Totalgroup_comm, color= Totalgroup_cols, edge.width = 1.9,
                  cut = 0.10, maximum = 1, vTrans = 100, edge.label.cex = 1.2,
                  details = FALSE, vsize=9, label.cex=1.3,
                  legend = FALSE, borders = TRUE)


set.seed(1)
nct_l_r = qgraph(input_NCTgraph_l_r, edge.labels = TRUE,
                  layout = L, theme = "Borkulo", title = "Left - Right",
                  title.cex = 3, labels = shortnames, nodeNames = longnames,
                  groups=Totalgroup_comm, color= Totalgroup_cols, edge.width = 1.9,
                  cut = 0.10, maximum = 1, vTrans = 100, edge.label.cex = 1.2,
                  details = FALSE, vsize=9, label.cex=1.3,
                  legend = FALSE, borders = TRUE)

set.seed(1)
nct_l_m = qgraph(input_NCTgraph_l_m, edge.labels = TRUE,
                  layout = L, theme = "Borkulo", title = "Left - 5SM",
                  title.cex = 3, labels = shortnames, nodeNames = longnames,
                  groups=Totalgroup_comm, color= Totalgroup_cols, edge.width = 1.9,
                  cut = 0.10, maximum = 1, vTrans = 100, edge.label.cex = 1.2,
                  details = FALSE, vsize=9, label.cex=1.3,
                  legend = FALSE, borders = TRUE)

dev.off()

```


```{r}
# Summary of results of NCTs
#NCT_r_m
#NCT_l_r
#NCT_l_m

#matrices where cell represent diff in values of edges
#that are statistically significant according to NCTs
#input_NCTgraph_r_m
#input_NCTgraph_l_r
#input_NCTgraph_l_m

             #### Option 1: absolute sum of differences in edge weight ####
#r_m
abs_diff_r_m = NCT_r_m$einv.real %>% 
  as.vector() %>% 
  abs() %>% 
  sum() #14.39907

#l_r
abs_diff_l_r = NCT_l_r$einv.real %>% 
  as.vector() %>% 
  abs() %>% 
  sum() #12.49714

#l_m
abs_diff_l_m = NCT_l_m$einv.real %>% 
  as.vector() %>% 
  abs() %>% 
  sum() #11.16066

          #### Option 2: absolute sum of differences in edge weight, ####
             #### only for edges that differ according to the NCT ####

#Total diff in edge weights (abs values)
#r_m
vector_r_m = input_NCTgraph_r_m %>% 
  as.vector() %>% 
  abs() %>% 
  sum() #8.87308

#l_r
vector_l_r = input_NCTgraph_l_r %>% 
  as.vector() %>% 
  abs() %>% 
  sum() #6.077991

#l_m
vector_l_m = input_NCTgraph_l_m %>% 
  as.vector() %>% 
  abs() %>% 
  sum() #5.259666

        #### Option 3: calculate cor between signed matrices ####
cor_r_m = cor(c(as.matrix(vote_r_data_net)), c(as.matrix(vote_m_data_net))) #0.5234926
cor_l_r = cor(c(as.matrix(vote_l_data_net)), c(as.matrix(vote_r_data_net))) #0.5889477
cor_l_m = cor(c(as.matrix(vote_l_data_net)), c(as.matrix(vote_m_data_net))) #0.7872863
```

```{r}
#Graph option 2
H4_2 = tibble(variable = c("Right - M5S", "Left - Right", "Left - M5S"),
                   dif = c(vector_r_m, vector_l_r, vector_l_m)) %>% 
  arrange(desc(dif)) %>% 
  ggplot(aes(x=reorder(variable, -dif), y = dif, fill=variable)) +
  geom_bar(stat="identity") +
  geom_text(aes(label= formattable::digits(dif, digits = 2)), parse = FALSE, vjust=-0.5, size=3) +
  labs(y = "Absolute edge difference", x = "") +
  scale_y_continuous(limits = c(0,10)) +
  theme(legend.position = "none") + 
  scale_fill_manual(values = c("#5b5b5b", "#8c8c8c", "#adadad"))

```

```{r}
#Graph option 3
H4_3 = tibble(variable = c("Right - M5S", "Left - Right", "Left - M5S"),
                   dif = c(cor_r_m, cor_l_r, cor_l_m)) %>% 
  arrange(desc(dif)) %>% 
  ggplot(aes(x=reorder(variable, -dif), y = dif, fill=variable)) +
  geom_bar(stat="identity") +
  geom_text(aes(label= formattable::digits(dif, digits = 2)), parse = FALSE, vjust=-0.5, size=3) +
  labs(y = "Correlation between matrices", x = "") +
  scale_y_continuous(limits = c(0,1)) +
  theme(legend.position = "none") + 
  scale_fill_manual(values = c("#5b5b5b", "#8c8c8c", "#adadad"))
```

```{r}
#Figure_4 multiplot
Figure_4 = H4_2 + plot_spacer() + H4_3 + plot_layout(widths = c(4, 0.5 ,4))

# Save the multiplot
ggsave(here("Output", "Article", "Figure_4.jpg"), Figure_4, width = 12, height = 6)
```


# Network descriptives
This code replicates descriptives of the networks used throughout the article

```{r}
#Figure 1

## Min edge weight
min_fig1 = att_net %>% 
  as.vector() %>%
  min()

## Max edge weight
max_fig1 = att_net %>% 
  as.vector() 
max_fig1 = max_fig1[max_fig1 != 1]
max_fig1 = max_fig1 %>%
 max()


## Node strength
strength_fig1 = centrality(att_net)
min_st_fig1 = min(strength_fig1$OutDegree)
max_st_fig1 = max(strength_fig1$OutDegree)

## Constraint
const_fig1 = mean(att_net)

## N° of zero cells
zerofig1 = sum(att_net <= 0.001)

## N° of non zero edges
nonzerofig1 = sum(att_net != 0)
```

```{r}
#Figure 2

## Point estimate and ci of each subgroup
mcon_pint_summary
mcon_edu_summary
```

```{r}
#Figure 3

## N° of non zero edges
n_left = (sum(vote_l_data_net != 0))/2
n_mov = (sum(vote_m_data_net != 0))/2
n_right = (sum(vote_r_data_net != 0))/2


## Density of each plot (Sum of the Absolute Value of Each Cell of a Matrix)
d_left = sum(abs(vote_l_data_net))
d_mov = sum(abs(vote_m_data_net))
d_right = sum(abs(vote_r_data_net))

```

```{r}
#NCT

## N° edges differing between each network pair
nnct_rm =  sum(input_NCTgraph_r_m != 0)
nnct_lr =  sum(input_NCTgraph_l_r != 0)
nnct_lm =  sum(input_NCTgraph_l_m != 0)

max_rm = max(input_NCTgraph_r_m)
max_lr = max(input_NCTgraph_l_r)
max_lm =  max(input_NCTgraph_l_m)
```

```{r}
#Figure 4

## average value of absolute edge weight in each vote bel syst (NON 0)
#left
avg_edg_l = vote_l_data_net %>% 
  abs() %>% 
  as.vector()

avg_edg_l = avg_edg_l[avg_edg_l != 0]
avg_edg_l = avg_edg_l[avg_edg_l != 1]

avg_edg_l = mean(avg_edg_l)

#right
avg_edg_m = vote_m_data_net %>% 
  abs() %>% 
  as.vector()

avg_edg_m = avg_edg_m[avg_edg_m != 0]
avg_edg_m = avg_edg_m[avg_edg_m != 1]

avg_edg_m = mean(avg_edg_m)

#Mov
avg_edg_r = vote_r_data_net %>% 
  abs() %>% 
  as.vector()

avg_edg_r = avg_edg_r[avg_edg_r != 0]
avg_edg_r = avg_edg_r[avg_edg_r != 1]

avg_edg_r = mean(avg_edg_r)

# Number of edges differing between matrices
ndiff_rm = (sum(vote_r_data_net != vote_m_data_net))/2
ndiff_lr = (sum(vote_l_data_net != vote_r_data_net))/2
ndiff_lm = (sum(vote_l_data_net != vote_m_data_net))/2

#theorethical max n of edges 
tmax = 19*18/2
```


